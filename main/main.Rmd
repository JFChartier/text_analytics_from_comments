---
title: "Modélisation des commentaires des agents en assurance de la personne"
author: "Jean-Francois Chartier"
date: "`r Sys.Date()`"
output: 
  html_document: 
    code_folding: hide
    fig_width: 5
    highlight: tango
    theme: united
    toc: yes
    toc_float: yes
editor_options: 
  chunk_output_type: console
---


```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

# lib
```{r}
library(magrittr)
#library(data.table)
library(stringr)
library(quanteda)
library(dplyr)
library(qdapRegex)
library(text2vec)



source("textPreprocessingFunctions.R")

```

# Data
```{r}

svdFromWiki300 = readRDS("~/datalab-nlp/JF Chartier/Data/SemanticModels/matrixV_svdFromWiki300.rds")

myFrenchStopwords = data.table::fread("~/datalab-nlp/JF Chartier/Data/SemanticModels/antidictionnaireFrancais.csv", header = F, encoding = "UTF-8")

comments_from_agents = data.table::fread("~/datalab-nlp/JF Chartier/Data/text_analytics_from_comments/comments_from_calls_2020.csv", header = T, encoding = "UTF-8")

```


# prétraitement des commentaires
```{r}
#french_dic = dictionary("~/.config/rstudio/dictionaries/languages-system/fr_FR.dic")
#hunspell::list_dictionaries()




comments_from_agents = comments_from_agents[comments_from_agents$Langue == "Français", ]
comments_from_agents = comments_from_agents[nchar(comments_from_agents$Commentaires_de_lagent) > 3 , ]


text_preprocessing_results = text_preprocessing(text_in_claims = comments_from_agents$Commentaires_de_lagent, myFrenchStopwords = myFrenchStopwords)




reduced_comments_space = getLatentVectorsOfComments(vectorizedCorpus = text_preprocessing_results$vectorizedCorpus, svd_v = svdFromWiki300$v, svd_d = svdFromWiki300$d, originalFeatures = svdFromWiki300$original.features)
  
```



```{r}
categorie_appel = comments_from_agents$Categorie_dappel %>% tolower() %>% stringr::str_squish()
# filtrer les categorie rares
categorie_appel_freq = table(categorie_appel) %>% is_less_than(5) %>% table(categorie_appel)[.] %>% names(.) #%>% categorie_appel[categorie_appel %in% .]
categorie_appel[categorie_appel %in% categorie_appel_freq] = "category_less_frequent_that_5"

vector_of_categorieAppel = quanteda::dfm_group(text_preprocessing_results$vectorizedCorpus %>% quanteda::as.dfm(), groups= categorie_appel)

reduced_categories_space = getLatentVectorsOfComments(vectorizedCorpus = vector_of_categorieAppel, svd_v = svdFromWiki300$v, svd_d = svdFromWiki300$d, originalFeatures = svdFromWiki300$original.features)

rownames(reduced_categories_space) = vector_of_categorieAppel@Dimnames$docs
    
```


```{r}

unique_word_in_comments = myTextCleaner(comments_from_agents$Commentaires_de_lagent) %>% myTextTokenizer(text = ., charNgram = 0, myFrenchStopwords = myFrenchStopwords, to_stemm = F) %>% unlist() %>% unique()


unique_word_preprocessed = text_preprocessing(text_in_claims = unique_word_in_comments, myFrenchStopwords = NULL)


reduced_word_space = getLatentVectorsOfComments(vectorizedCorpus = unique_word_preprocessed$vectorizedCorpus, svd_v = svdFromWiki300$v, svd_d = svdFromWiki300$d, originalFeatures = svdFromWiki300$original.features)
rownames(reduced_word_space) = unique_word_in_comments

```


```{r}

similarity_between_cat_word=text2vec::sim2(x = as.matrix(reduced_categories_space), y = as.matrix(reduced_word_space), method = "cosine", norm = "none") #%>% set_rownames(dat)

```
# Show result
```{r}

i=order(similarity_between_cat_word[1,], decreasing = T)[1:50]
result=data.frame(word=colnames(similarity_between_cat_word)[i], similarity=similarity_between_cat_word[,i])


DT::datatable(similarity_between_cat_word[,10], rownames = T, filter="none", selection="none", options = list(pageLength = 10, scrollX=T), caption="Codes d'assignation les plus pertinent pour la requête")
```




